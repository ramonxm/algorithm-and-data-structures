<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-concepts/big-o-notation" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Notação Big O | Brain</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://ramonxm.github.io/brain/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://ramonxm.github.io/brain/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://ramonxm.github.io/brain/docs/concepts/big-o-notation"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Notação Big O | Brain"><meta data-rh="true" name="description" content="Big O fala sobre como os algoritmos ESCALAM dependendo do tamanho da entrada, e não necessariamente sobre o desempenho do algoritmo."><meta data-rh="true" property="og:description" content="Big O fala sobre como os algoritmos ESCALAM dependendo do tamanho da entrada, e não necessariamente sobre o desempenho do algoritmo."><link data-rh="true" rel="icon" href="/brain/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://ramonxm.github.io/brain/docs/concepts/big-o-notation"><link data-rh="true" rel="alternate" href="https://ramonxm.github.io/brain/docs/concepts/big-o-notation" hreflang="en"><link data-rh="true" rel="alternate" href="https://ramonxm.github.io/brain/docs/concepts/big-o-notation" hreflang="x-default"><link rel="stylesheet" href="/brain/assets/css/styles.fcaff2be.css">
<script src="/brain/assets/js/runtime~main.ec4bb59a.js" defer="defer"></script>
<script src="/brain/assets/js/main.f4be4e9c.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/brain/"><b class="navbar__title text--truncate">Ramon Xavier</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/brain/docs/concepts">Conceitos</a><a class="navbar__item navbar__link" href="/brain/docs/data-structures">Estruturas de Dados</a><a class="navbar__item navbar__link" href="/brain/docs/algorithms">Algoritmos</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/brain/docs/concepts/big-o-notation" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li></ul></div><a href="https://github.com/ramonxm/algorithm-and-data-structures" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite" aria-pressed="true"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/brain/docs/intro">Introdução</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/brain/docs/concepts/">Conceitos Fundamentais</a><button aria-label="Collapse sidebar category &#x27;Conceitos Fundamentais&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/brain/docs/concepts/big-o-notation">Notação Big O</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/brain/docs/concepts/fifo">FIFO (First In, First Out)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/brain/docs/concepts/lifo">LIFO (Último a Entrar, Primeiro a Sair)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/brain/docs/concepts/memory-stack-heap">Memória Heap e Stack</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/brain/docs/concepts/swap">Swap</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/brain/docs/concepts/thread">Threads</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/brain/docs/data-structures/">Estruturas de Dados</a><button aria-label="Expand sidebar category &#x27;Estruturas de Dados&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/brain/docs/algorithms/">Algoritmos</a><button aria-label="Expand sidebar category &#x27;Algoritmos&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/brain/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/brain/docs/concepts/"><span itemprop="name">Conceitos Fundamentais</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Notação Big O</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Notação Big O</h1></header>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="big-o-fala-sobre-como-os-algoritmos-escalam-dependendo-do-tamanho-da-entrada-e-não-necessariamente-sobre-o-desempenho-do-algoritmo">Big O <strong>fala sobre como os algoritmos ESCALAM</strong> dependendo do <strong>tamanho</strong> da <strong>entrada</strong>, e <strong>não</strong> necessariamente sobre o <strong>desempenho</strong> do <strong>algoritmo</strong>.<a href="#big-o-fala-sobre-como-os-algoritmos-escalam-dependendo-do-tamanho-da-entrada-e-não-necessariamente-sobre-o-desempenho-do-algoritmo" class="hash-link" aria-label="Direct link to big-o-fala-sobre-como-os-algoritmos-escalam-dependendo-do-tamanho-da-entrada-e-não-necessariamente-sobre-o-desempenho-do-algoritmo" title="Direct link to big-o-fala-sobre-como-os-algoritmos-escalam-dependendo-do-tamanho-da-entrada-e-não-necessariamente-sobre-o-desempenho-do-algoritmo">​</a></h3>
<aside><p>É uma forma de <strong>denotar o desempenho do algoritmo</strong>, mas <strong>não</strong> é uma <strong>medida de desempenho</strong></p></aside>
<aside><p>Big O <strong>não mede o tempo exato de execução</strong> de um algoritmo, mas sim <strong>como o tempo cresce</strong> conforme o tamanho da entrada aumenta. 📈</p></aside>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="big-o-pode-ser-usado-para-medir-tanto-a-complexidade-de-tempo-quanto-a-complexidade-de-espaço-de-um-algoritmo">Big O pode ser usado para medir tanto a <em>complexidade de tempo</em> quanto a <em>complexidade de espaço</em> de um algoritmo.<a href="#big-o-pode-ser-usado-para-medir-tanto-a-complexidade-de-tempo-quanto-a-complexidade-de-espaço-de-um-algoritmo" class="hash-link" aria-label="Direct link to big-o-pode-ser-usado-para-medir-tanto-a-complexidade-de-tempo-quanto-a-complexidade-de-espaço-de-um-algoritmo" title="Direct link to big-o-pode-ser-usado-para-medir-tanto-a-complexidade-de-tempo-quanto-a-complexidade-de-espaço-de-um-algoritmo">​</a></h3>
<ul>
<li><strong>Complexidade de Tempo</strong>: Relaciona-se ao tempo de execução (runtime), ou seja, quanto tempo leva para executar. <strong>Mais comum em entrevistas</strong></li>
<li><strong>Complexidade de Espaço</strong>: Relaciona-se a quanto de memória adicional precisamos alocar</li>
</ul>
<hr>
<blockquote>
<p>A <strong>análise assintótica</strong> é a forma de analisar como um algoritmo se comporta em termos de tempo e memória conforme o tamanho da entrada cresce.</p>
</blockquote>
<hr>
<h1>Principais notações do BIG O:</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="o1--complexidade-constante-"><strong>O(1) – Complexidade Constante →</strong><a href="#o1--complexidade-constante-" class="hash-link" aria-label="Direct link to o1--complexidade-constante-" title="Direct link to o1--complexidade-constante-">​</a></h2>
<blockquote>
<p><em>&quot;Acender uma luz com um interruptor – sempre leva o mesmo tempo, independente do tamanho da casa.&quot;</em></p>
</blockquote>
<ul>
<li>
<p><strong>🧠 Explicado usando a Técnica Feynman</strong></p>
<p>Imagine que você tem uma caixa de objetos e precisa encontrar um item específico nela. Agora, em vez de procurar em cada item da caixa, você já sabe exatamente onde ele está. Ao abrir a caixa, você vai diretamente ao item certo, sem precisar verificar nada mais.
O tempo que você leva para encontrar o item é o mesmo, não importa quantos itens estejam na caixa. Isso é o que acontece com a complexidade <strong>O(1)</strong>.
Independentemente do tamanho da entrada, o tempo de execução do algoritmo é constante.</p>
<p><strong>O(1)</strong> é complexidade constante, significando que o tempo de execução do algoritmo não depende do tamanho da entrada. Independentemente de quantos elementos existam, o tempo ou memória consumidos são os mesmos.</p>
</li>
<li>
<p><strong>🧐 Exemplo Prático</strong></p>
<ul>
<li>Acessar o primeiro elemento de um array: <code>arr[0]</code></li>
<li>Verificar se um número é par: <code>num % 2 == 0</code></li>
<li>Inserir ou remover um item do topo de uma pilha</li>
</ul>
</li>
<li>
<p><strong>⏰ Sobre Complexidade Temporal</strong></p>
<p><strong>Tempo constante</strong>, significando que independentemente do tamanho da entrada, o algoritmo tem o mesmo tempo de execução.</p>
<p>O tempo de execução não muda, seja o tamanho da entrada pequeno ou grande. O algoritmo sempre leva o mesmo tempo para executar.</p>
<p><strong>⏰ Exemplos de O(1) – Tempo</strong></p>
<ul>
<li>Acessar um índice específico do array → <em>arr[0]</em></li>
<li>Verificar se um número é par → <em>num % 2 == 0</em></li>
<li>Inserir/remover um elemento no topo de uma pilha</li>
<li>Exemplo de algoritmos O(1) →<!-- -->
<ul>
<li>Encontrar o primeiro elemento de um array</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>👩🏼‍🚀 Sobre Complexidade Espacial</strong></p>
<p><strong>Memória constante</strong>, significando que o espaço alocado não cresce com a entrada.</p>
<p>O espaço de memória também não varia com o tamanho da entrada. O algoritmo usa a mesma quantidade de memória independentemente do número de elementos.</p>
<p>💾 <strong>Exemplos de O(1) – Memória</strong></p>
<ul>
<li>Criar uma variável e armazenar um valor fixo (int x = 10;)</li>
<li>Trocar valores de duas variáveis (a, b = b, a)</li>
</ul>
</li>
<li>
<p><strong>🔍 Como identificar se é O(1)?</strong></p>
<p><strong>Como identificar</strong>:</p>
<p>Se o algoritmo realiza uma única operação, independentemente do tamanho da entrada, é <strong>O(1)</strong>. Em outras palavras, o número de passos para completar a tarefa não muda com o aumento da entrada.</p>
<p><strong>Exemplo</strong>:</p>
<ul>
<li>Se você acessa um elemento do array diretamente, como <code>arr[5]</code>, ou troca valores de duas variáveis, o tempo para essas operações é constante.</li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="olog-n--complexidade-logarítmica-"><strong>O(log n) – Complexidade Logarítmica →</strong><a href="#olog-n--complexidade-logarítmica-" class="hash-link" aria-label="Direct link to olog-n--complexidade-logarítmica-" title="Direct link to olog-n--complexidade-logarítmica-">​</a></h2>
<blockquote>
<p><em>&quot;Encontrar um nome na lista telefônica dividindo as páginas ao meio a cada vez.&quot;</em></p>
</blockquote>
<ul>
<li>
<p><strong>🧠 Explicado usando a Técnica Feynman</strong></p>
<p>Imagine que você tem um livro com <strong>1.000 páginas</strong> e quer encontrar uma palavra específica. Se você folhear página por página, do início ao fim, poderia levar muito tempo (O(n)).</p>
<p>Agora, imagine um método mais inteligente: <strong>você abre o livro no meio</strong> e vê se a palavra está antes ou depois daquela página. Se estiver antes, você ignora a metade de trás e olha apenas a metade da frente. Se estiver depois, ignora a metade da frente e foca na metade de trás.</p>
<p>Repita este processo, cortando o problema pela metade a cada passo. Em muito poucos passos, você encontra a palavra! 🎯</p>
<p>🔢 <strong>Isso é O(log n)</strong> → Em vez de processar <strong>todos</strong> os elementos, você reduz drasticamente a quantidade de verificações.</p>
</li>
<li>
<p><strong>🧐 Exemplo Prático</strong></p>
<ul>
<li>Você tem um array ordenado e quer encontrar um número.</li>
<li>Comece olhando o meio:<!-- -->
<ul>
<li>Se for o número que procuramos, fim! 🎉</li>
<li>Se o número for menor, olhamos apenas a metade da esquerda.</li>
<li>Se for maior, olhamos apenas a metade da direita.</li>
</ul>
</li>
<li>Em cada passo, cortamos o problema pela <strong>metade</strong> até encontrar o resultado.</li>
</ul>
</li>
<li>
<p><strong>⏰ Sobre Complexidade Temporal</strong></p>
<p>O tempo de execução cresce muito mais devagar à medida que o tamanho da entrada aumenta, em comparação com algoritmos <strong>O(n)</strong> ou <strong>O(n²)</strong>.</p>
<p>⏰ <strong>Exemplos de O(log n) - Temporal</strong></p>
<ul>
<li><strong>Busca binária</strong>: A cada iteração, o número de elementos possíveis é reduzido pela metade.</li>
<li><strong>Encontrar o elemento no meio de uma lista ordenada</strong> e eliminar metade das opções em cada iteração.</li>
</ul>
</li>
<li>
<p><strong>👩🏼‍🚀 Sobre Complexidade Espacial</strong></p>
<p>A memória utilizada por um algoritmo <strong>O(log n)</strong> também cresce de forma logarítmica em relação ao tamanho da entrada. Isso significa que, mesmo que o número de elementos cresça, o espaço utilizado por cada operação não aumenta drasticamente.</p>
<p><strong>👩🏼‍🚀 Exemplos de O(log n) - Espacial</strong></p>
<ul>
<li><strong>Recursão em busca binária</strong>, onde a pilha de chamadas cresce logaritmicamente à medida que o tamanho da entrada diminui.</li>
<li>Algoritmos de <strong>divisão e conquista</strong> podem precisar de espaço extra para armazenar subproblemas, mas o espaço usado não cresce linearmente.</li>
</ul>
</li>
<li>
<p><strong>🔍 Como identificar se é O(log n)?</strong></p>
<p><strong>Como identificar</strong>:</p>
<p>Se você perceber que, a cada passo, o tamanho do problema diminui significativamente — por exemplo, sempre pela metade — o algoritmo provavelmente tem complexidade <strong>O(log n)</strong>. Isso acontece porque o número de iterações necessárias cresce muito mais devagar do que o tamanho da entrada.</p>
<p><strong>Exemplo</strong>:</p>
<ul>
<li>Se você está dividindo o problema pela metade a cada iteração, como em uma busca binária, o tempo de execução será <strong>O(log n)</strong>.</li>
<li>Quando o algoritmo realiza uma busca ou divisão de dados que elimina metade das opções a cada passo, como na <strong>busca binária</strong>, você pode identificar que é <strong>O(log n)</strong>.</li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="on--complexidade-linear-"><strong>O(n) – Complexidade Linear →</strong><a href="#on--complexidade-linear-" class="hash-link" aria-label="Direct link to on--complexidade-linear-" title="Direct link to on--complexidade-linear-">​</a></h2>
<blockquote>
<p><em>&quot;Ler um livro do começo ao fim sem pular páginas.&quot;</em></p>
</blockquote>
<ul>
<li>
<p><strong>🧠 Explicado usando a Técnica Feynman</strong></p>
<p>Imagine que você tem uma fila de pessoas esperando para fazer uma tarefa. Se a pessoa na frente terminar, ela chama a próxima, e assim por diante, até que todos tenham feito a tarefa. O tempo necessário para todos fazerem a tarefa depende diretamente de quantas pessoas estão na fila. Se houver mais pessoas na fila, o tempo total aumenta na mesma proporção.
Esse é o conceito de <strong>O(n)</strong>: o tempo de execução aumenta linearmente com o tamanho da entrada.
O número de operações que o algoritmo realiza aumenta conforme o número de itens que ele precisa processar.</p>
</li>
<li>
<p><strong>🧐 Exemplo Prático</strong></p>
<p>Passo a passo:</p>
<ol>
<li>Você tem um array de 10 elementos e quer somar todos os números nele.</li>
<li>Você começa do primeiro elemento e vai até o último, somando um por um.</li>
<li>O número de passos (operações) que o algoritmo faz é igual ao número de elementos no array.</li>
<li>Portanto, se o array tiver 100 elementos, o algoritmo fará 100 operações; se tiver 1.000, ele fará 1.000 operações.</li>
</ol>
<p><strong>Outro exemplo:</strong></p>
<ul>
<li><strong>Buscar um elemento em um array não ordenado</strong>: O algoritmo precisa olhar cada elemento até encontrar o que está procurando.</li>
<li><strong>Imprimir todos os elementos de um array</strong>: O tempo de execução aumenta com o número de elementos que você precisa imprimir.</li>
</ul>
</li>
<li>
<p><strong>⏰ Sobre Complexidade Temporal</strong></p>
<p><strong>O(n)</strong> é linear. O tempo de execução cresce na mesma proporção que o tamanho da entrada.
Se você tem 1.000 itens para processar, o algoritmo fará 1.000 operações, e se você tiver 10.000 itens, fará 10.000 operações.</p>
<p>⏰ <strong>Exemplos de O(n) - Temporal</strong></p>
<ul>
<li><strong>Soma de todos os elementos de um array</strong>: O algoritmo percorre cada elemento uma vez para somá-los.</li>
<li><strong>Buscar um item em um array não ordenado</strong>: O algoritmo verifica cada elemento até encontrar o item.</li>
<li><strong>Imprimir cada valor de uma lista</strong>: A operação de imprimir cada item exige uma operação por item na lista.</li>
</ul>
</li>
<li>
<p><strong>👩🏼‍🚀 Sobre Complexidade Espacial</strong></p>
<ul>
<li><strong>Armazenar cópias dos elementos de uma lista</strong>: Se o algoritmo precisa criar uma nova lista para armazenar os elementos, o espaço necessário cresce com o número de elementos.</li>
<li><strong>Contar o número de vezes que um valor aparece em um array</strong>: Para cada item que o algoritmo verifica, ele precisa de um pouco mais de memória para armazenar a contagem.</li>
</ul>
</li>
<li>
<p><strong>🔍 Como identificar se é O(n)?</strong></p>
<p><strong>Como identificar</strong>:</p>
<p>Se o algoritmo faz uma operação para cada item na entrada (ou em uma parte significativa da entrada), o tempo de execução é <strong>O(n)</strong>. O número de operações cresce proporcionalmente ao tamanho da entrada.</p>
<p><strong>Exemplo</strong>:</p>
<ul>
<li>Se você precisa percorrer uma lista e realizar uma operação em cada item (como somar ou verificar um valor), isso será <strong>O(n)</strong> porque o número de operações aumenta conforme o tamanho da lista.</li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="on-log-n--complexidade-quasilinear-"><strong>O(n log n) – Complexidade Quasilinear →</strong><a href="#on-log-n--complexidade-quasilinear-" class="hash-link" aria-label="Direct link to on-log-n--complexidade-quasilinear-" title="Direct link to on-log-n--complexidade-quasilinear-">​</a></h2>
<blockquote>
<p><em>&quot;Organizar um baralho dividindo as cartas em pilhas menores e juntando depois.&quot;</em></p>
</blockquote>
<ul>
<li>
<p><strong>🧠 Explicado usando a Técnica Feynman</strong></p>
<p>Imagine que você tem um grande número de dados e quer organizá-los de alguma forma, como em um array. Agora, em vez de olhar para todos os dados de uma vez, você divide em partes menores e faz algo com essas partes (como ordená-las) para depois juntar tudo de novo.
Esse processo de dividir, ordenar e juntar faz o tempo de execução crescer de maneira um pouco mais complexa do que um simples <strong>O(n)</strong>, mas muito mais rápido do que o <strong>O(n²)</strong>.</p>
<p>O &quot;log n&quot; vem do processo de dividir repetidamente os dados em partes menores, e o &quot;n&quot; vem de ter que processar todos os dados ao longo do caminho.</p>
</li>
<li>
<p><strong>🧐 Exemplo Prático</strong></p>
<ul>
<li>Exemplos de algoritmos que usam:<!-- -->
<ul>
<li>ORDENAÇÃO (quicksort, mergesort)</li>
<li>DIVIDIR E CONQUISTAR</li>
</ul>
</li>
<li>Digamos que você tenha um array de <strong>n</strong> elementos.</li>
<li>Você divide esse array em dois subarrays menores até que cada subarray tenha um único elemento.</li>
<li>Depois, você começa a juntar esses subarrays ordenando-os, de forma que no final você tenha o array inteiro ordenado.</li>
<li>O tempo para dividir os arrays é <strong>O(log n)</strong>, e o tempo para percorrer todos os <strong>n</strong> elementos enquanto você faz a ordenação é <strong>O(n)</strong>.</li>
<li>Juntando os dois, temos <strong>O(n log n)</strong>.</li>
</ul>
</li>
<li>
<p><strong>⏰ Sobre Complexidade Temporal</strong></p>
<p><strong>O(n log n)</strong> significa que o tempo de execução aumenta conforme o número de elementos cresce, mas de uma forma mais controlada do que <strong>O(n²)</strong>.</p>
<p>A ordem de grandeza do tempo de execução é mais eficiente, o que faz esse tipo de algoritmo ser muito útil para problemas grandes, como ordenação de dados.</p>
<p>⏰ <strong>Exemplos de O(n log n) - Temporal</strong></p>
<ul>
<li><strong>Merge Sort</strong>: Um dos algoritmos mais conhecidos para ordenar dados com <strong>O(n log n)</strong>.</li>
<li><strong>Quick Sort</strong>: Outro algoritmo de ordenação que tem um desempenho de <strong>O(n log n)</strong>, mas em alguns casos pode ter desempenho pior se não for bem implementado.</li>
</ul>
</li>
<li>
<p><strong>👩🏼‍🚀 Sobre Complexidade Espacial</strong></p>
<p><strong>O(n log n)</strong> pode envolver o uso de memória extra para armazenar os subarrays temporários durante o processo de divisão e junção.
Dependendo do algoritmo, pode ser necessário mais espaço para armazenar esses dados temporários.</p>
<p>💾 <strong>Exemplos de O(n log n) - Espacial</strong></p>
<ul>
<li><strong>Merge Sort</strong>: Durante o processo de ordenação, o <strong>Merge Sort</strong> precisa de espaço extra proporcional a <strong>O(n)</strong> para armazenar subarrays temporários.</li>
<li><strong>Quick Sort</strong>: O espaço extra usado pelo <strong>Quick Sort</strong> pode ser <strong>O(log n)</strong> no melhor caso, mas pode ser maior dependendo de como a recursão é realizada.</li>
</ul>
</li>
<li>
<p><strong>🔍 Como identificar se é O(n log n)?</strong></p>
<ul>
<li>Para identificar se um algoritmo tem <strong>O(n log n)</strong> de complexidade, é importante procurar por processos que envolvem dividir um conjunto de dados em partes menores e realizar uma operação sobre cada uma dessas partes, como ordenar.
Esses algoritmos tendem a ter uma combinação de um loop que percorre todos os <strong>n</strong> dados e um processo de divisão recursiva ou logarítmica.</li>
</ul>
<p><strong>Como identificar:</strong></p>
<ol>
<li>Se você vê uma <strong>divisão repetitiva</strong> dos dados, como no caso de <strong>Merge Sort</strong> ou <strong>Quick Sort</strong>.</li>
<li>Se cada operação de divisão tem um custo de <strong>O(log n)</strong>, mas você ainda precisa passar por todos os dados <strong>n</strong>.</li>
<li>Quando o tempo de execução é uma combinação de linear e logarítmica, como <strong>n log n</strong>.</li>
</ol>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="on--complexidade-quadrática-"><strong>O(n²) – Complexidade Quadrática →</strong><a href="#on--complexidade-quadrática-" class="hash-link" aria-label="Direct link to on--complexidade-quadrática-" title="Direct link to on--complexidade-quadrática-">​</a></h2>
<blockquote>
<p><em>&quot;Comparar cada aluno da turma com todos os outros para descobrir quem é mais alto.&quot;</em></p>
</blockquote>
<ul>
<li>
<p><strong>🧠 Explicado usando a Técnica Feynman</strong></p>
<p><strong>Viu loop dentro de um loop ou Bubble sort? Pode cravar que é O(n²)!</strong>
Imagine que você tem uma lista de pessoas e quer comparar cada uma delas com todas as outras para encontrar pares com algo em comum. No começo, você compara a primeira pessoa com todas as outras, depois a segunda com todas as outras (exceto a primeira, porque já foi comparada), e assim por diante.
Isso cria uma cascata de comparações, onde cada novo elemento faz o número de interações crescer de forma quadrática. Se tivermos 10 elementos, fazemos <strong>100 comparações</strong>; se tivermos 1.000, fazemos <strong>1.000.000</strong>!
Isso explica por que algoritmos <strong>O(n²)</strong> ficam lentos com entradas grandes.</p>
</li>
<li>
<p><strong>🧐 Exemplo Prático</strong></p>
<ul>
<li>Você tem um array de <strong>n</strong> elementos.</li>
<li>Você precisa comparar cada elemento com todos os outros.</li>
<li>O primeiro elemento será comparado com <strong>n - 1</strong> elementos.</li>
<li>O segundo elemento será comparado com <strong>n - 2</strong> elementos.</li>
<li>Isso se repete até o último elemento, criando <strong>n × n</strong> operações.</li>
</ul>
</li>
<li>
<p><strong>⏰ Sobre Complexidade Temporal</strong></p>
<p><strong>O(n²)</strong> significa que à medida que <strong>n</strong> cresce, o tempo de execução cresce proporcionalmente ao quadrado desse número.
Isso significa que um pequeno aumento no tamanho do input pode resultar em um aumento <strong>exponencial</strong> no tempo de execução.</p>
<p>⏰ <strong>Exemplos de O(n²) - Temporal</strong></p>
<ul>
<li><strong>Bubble Sort</strong>: Cada elemento precisa ser comparado com todos os outros.</li>
<li><strong>Selection Sort</strong>: Busca pelo menor elemento e o troca de posição várias vezes.</li>
<li><strong>Algoritmo ingênuo para encontrar pares duplicados</strong>: Um loop dentro de outro loop para verificar se existem elementos iguais.</li>
</ul>
</li>
<li>
<p><strong>👩🏼‍🚀 Sobre Complexidade Espacial</strong></p>
<p><strong>O(n²)</strong> pode, em alguns casos, exigir uma grande quantidade de memória extra se for necessário armazenar pares, matrizes ou listas auxiliares durante as operações.</p>
<p>💾 <strong>Exemplos de O(n²) - Espacial</strong></p>
<ul>
<li><strong>Multiplicação de Matrizes Ingênua</strong>: Cada célula da matriz resultante requer múltiplas iterações pelos dados.</li>
<li><strong>Criação de tabelas auxiliares</strong> para armazenar relações entre elementos (exemplo: uma tabela de adjacência em grafos).</li>
</ul>
</li>
<li>
<p><strong>🔍 Como identificar se é O(n²)?</strong></p>
<ul>
<li>Para identificar se um algoritmo tem <strong>O(n²)</strong> de complexidade, procure por <strong>loops aninhados</strong> onde cada iteração percorre toda a entrada para cada elemento.</li>
</ul>
<p><strong>Como identificar:</strong></p>
<ol>
<li>Se há <strong>dois loops aninhados</strong> que percorrem o mesmo conjunto de dados.</li>
<li>Se a quantidade de operações cresce <strong>muito rápido</strong> conforme o input aumenta.</li>
<li>Se um problema envolve comparar <strong>todos os elementos com todos os outros</strong> (como em alguns algoritmos de ordenação).</li>
</ol>
</li>
</ul>
<hr>
<h1>Outras notações do BIG O (menos comuns):</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="o2ⁿ--complexidade-exponencial-"><strong>O(2ⁿ) – Complexidade Exponencial →</strong><a href="#o2ⁿ--complexidade-exponencial-" class="hash-link" aria-label="Direct link to o2ⁿ--complexidade-exponencial-" title="Direct link to o2ⁿ--complexidade-exponencial-">​</a></h2>
<blockquote>
<p><em>&quot;Testar todas as formas possíveis de resolver um cubo mágico.&quot;</em></p>
</blockquote>
<ul>
<li>
<p><strong>🧠 Explicado usando a Técnica Feynman</strong></p>
<p>Imagine que você tem um cofre e quer descobrir a senha, mas não sabe quantos números precisa testar.</p>
<p>Cada vez que você adiciona um dígito a mais, o número de possibilidades dobra. Se a senha tiver 1 dígito, há 2 possibilidades (0 ou 1).</p>
<p>Se tiver 2 dígitos, há 4 possibilidades (00, 01, 10, 11). Com 3 dígitos, já são 8 possibilidades.</p>
<p>Assim, conforme o número de elementos aumenta, o número de operações cresce exponencialmente, dobrando a cada nova unidade adicionada.</p>
</li>
<li>
<p><strong>🧐 Exemplo Prático</strong></p>
<ul>
<li>Você precisa gerar <strong>todas as combinações possíveis</strong> de um conjunto.</li>
<li>Se há <strong>n elementos</strong>, cada um pode estar <strong>presente ou ausente</strong> na combinação.</li>
<li>Isso cria <strong>2ⁿ possibilidades</strong> de subconjuntos.</li>
<li>Para <strong>n = 3</strong>, as combinações possíveis seriam:<!-- -->
<ul>
<li><code>{}</code></li>
<li><code>{A}</code></li>
<li><code>{B}</code></li>
<li><code>{C}</code></li>
<li><code>{A, B}</code></li>
<li><code>{A, C}</code></li>
<li><code>{B, C}</code></li>
<li><code>{A, B, C}</code></li>
</ul>
</li>
<li>Para <strong>n = 4</strong>, já teríamos <strong>16 possibilidades</strong>.</li>
<li>Para <strong>n = 10</strong>, já seriam <strong>1024 possibilidades</strong>. 😯</li>
</ul>
</li>
<li>
<p><strong>⏰ Sobre Complexidade Temporal</strong></p>
<p><strong>O(2ⁿ)</strong> significa que, conforme o input cresce, o tempo de execução <strong>dobra</strong> a cada novo elemento. Isso torna esses algoritmos extremamente ineficientes para inputs grandes.</p>
<p>⏰ <strong>Exemplos de O(2ⁿ) - Temporal</strong></p>
<ul>
<li><strong>Problema do subconjunto</strong>: Gerar todas as combinações possíveis de um conjunto.</li>
<li><strong>Problema da Mochila (Força Bruta)</strong>: Testar todas as combinações possíveis de itens para encontrar o melhor conjunto.</li>
<li><strong>Fibonacci Recursivo (sem otimização)</strong>: A versão ingênua da sequência de Fibonacci, onde cada chamada recursiva cria duas novas chamadas.</li>
</ul>
</li>
<li>
<p><strong>👩🏼‍🚀 Sobre Complexidade Espacial</strong></p>
<p><strong>O(2ⁿ)</strong> pode exigir <strong>muito espaço na memória</strong>, especialmente quando todas as possibilidades precisam ser armazenadas antes da execução.</p>
<p>💾 <strong>Exemplos de O(2ⁿ) - Espacial</strong></p>
<ul>
<li><strong>Armazenamento de todas as combinações de um conjunto</strong>.</li>
<li><strong>Backtracking em problemas de busca exaustiva</strong>, onde todas as opções precisam ser mantidas na pilha de chamadas da recursão.</li>
</ul>
</li>
<li>
<p><strong>🔍 Como identificar se é O(2ⁿ)?</strong></p>
<ul>
<li>Se o número de operações <strong>dobra</strong> a cada novo elemento adicionado, você provavelmente está lidando com <strong>O(2ⁿ)</strong>.</li>
</ul>
<p><strong>Como identificar:</strong></p>
<ol>
<li>Se o algoritmo envolve <strong>gerar todas as combinações possíveis</strong> de um conjunto.</li>
<li>Se a solução usa <strong>recursão exponencial</strong>, onde cada chamada gera <strong>duas ou mais chamadas recursivas</strong>.</li>
<li>Se a quantidade de operações cresce <strong>extremamente rápido</strong>, tornando o algoritmo inviável para inputs grandes.</li>
</ol>
</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="on--complexidade-de-raiz-quadrada-"><strong>O(√n) – Complexidade de Raiz Quadrada →</strong><a href="#on--complexidade-de-raiz-quadrada-" class="hash-link" aria-label="Direct link to on--complexidade-de-raiz-quadrada-" title="Direct link to on--complexidade-de-raiz-quadrada-">​</a></h2>
<blockquote>
<p><em>&quot;Subir uma escada pulando degraus para chegar mais rápido ao topo.&quot;</em></p>
</blockquote>
<ul>
<li>
<p><strong>🧠 Explicado usando a Técnica Feynman</strong></p>
<p>Imagine que você precisa encontrar um número específico dentro de <strong>n</strong> elementos, mas, ao invés de verificar todos um por um (<strong>O(n)</strong>), você pode <strong>pular</strong> de um grupo para outro, reduzindo drasticamente a quantidade de verificações.
Por exemplo, se você tivesse <strong>100 elementos</strong>, ao invés de checar todos, você poderia <strong>dividir em blocos</strong> e testar apenas <strong>√100 = 10 elementos</strong>.
Esse comportamento aparece em problemas onde é possível reduzir a busca para a raiz quadrada do input.</p>
</li>
<li>
<p><strong>🧐 Exemplo Prático</strong></p>
<ul>
<li>Você precisa encontrar um número <strong>primo</strong> menor que <strong>n</strong>.</li>
<li>Ao invés de testar divisibilidade até <strong>n</strong>, você só precisa verificar até <strong>√n</strong>.</li>
<li>Exemplo: Para verificar se <strong>37 é primo</strong>, você não precisa testar divisibilidade por todos os números até 37, basta testar até <strong>√37 ≈ 6</strong>.</li>
<li>Se nenhum número até 6 divide 37, então 37 é primo.</li>
</ul>
</li>
<li>
<p><strong>⏰ Sobre Complexidade Temporal</strong></p>
<p><strong>O(√n)</strong> significa que o tempo de execução cresce com a raiz quadrada do tamanho da entrada.
Isso é mais eficiente que <strong>O(n)</strong> para entradas grandes.</p>
<p>⏰ <strong>Exemplos de O(√n) - Temporal</strong></p>
<ul>
<li><strong>Verificação de primalidade</strong>: Testar se um número é primo.</li>
<li><strong>Encontrar todos os divisores de um número</strong>: Você só precisa testar até a raiz quadrada do número.</li>
</ul>
</li>
<li>
<p><strong>👩🏼‍🚀 Sobre Complexidade Espacial</strong></p>
<p><strong>O(√n)</strong> geralmente não requer muito espaço adicional, pois a maioria das operações pode ser feita in-place.</p>
<p>💾 <strong>Exemplos de O(√n) - Espacial</strong></p>
<ul>
<li><strong>Armazenamento de divisores</strong>: Em alguns casos, você pode precisar armazenar os divisores encontrados.</li>
<li><strong>Buffer temporário</strong>: Para algumas operações matemáticas que trabalham com blocos de tamanho √n.</li>
</ul>
</li>
<li>
<p><strong>🔍 Como identificar se é O(√n)?</strong></p>
<p><strong>Como identificar:</strong></p>
<ol>
<li>Se o algoritmo trabalha com <strong>blocos</strong> ou <strong>grupos</strong> de tamanho √n.</li>
<li>Se envolve <strong>operações matemáticas</strong> onde você só precisa verificar até a raiz quadrada do número.</li>
<li>Se há uma <strong>otimização</strong> que permite pular verificações baseada na raiz quadrada do tamanho da entrada.</li>
</ol>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/ramonxm/brain/tree/main/docs/concepts/big-o-notation.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/brain/docs/concepts/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Conceitos Fundamentais</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/brain/docs/concepts/fifo"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">FIFO (First In, First Out)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#big-o-fala-sobre-como-os-algoritmos-escalam-dependendo-do-tamanho-da-entrada-e-não-necessariamente-sobre-o-desempenho-do-algoritmo" class="table-of-contents__link toc-highlight">Big O <strong>fala sobre como os algoritmos ESCALAM</strong> dependendo do <strong>tamanho</strong> da <strong>entrada</strong>, e <strong>não</strong> necessariamente sobre o <strong>desempenho</strong> do <strong>algoritmo</strong>.</a></li><li><a href="#big-o-pode-ser-usado-para-medir-tanto-a-complexidade-de-tempo-quanto-a-complexidade-de-espaço-de-um-algoritmo" class="table-of-contents__link toc-highlight">Big O pode ser usado para medir tanto a <em>complexidade de tempo</em> quanto a <em>complexidade de espaço</em> de um algoritmo.</a></li><li><a href="#o1--complexidade-constante-" class="table-of-contents__link toc-highlight"><strong>O(1) – Complexidade Constante →</strong></a></li><li><a href="#olog-n--complexidade-logarítmica-" class="table-of-contents__link toc-highlight"><strong>O(log n) – Complexidade Logarítmica →</strong></a></li><li><a href="#on--complexidade-linear-" class="table-of-contents__link toc-highlight"><strong>O(n) – Complexidade Linear →</strong></a></li><li><a href="#on-log-n--complexidade-quasilinear-" class="table-of-contents__link toc-highlight"><strong>O(n log n) – Complexidade Quasilinear →</strong></a></li><li><a href="#on--complexidade-quadrática-" class="table-of-contents__link toc-highlight"><strong>O(n²) – Complexidade Quadrática →</strong></a></li><li><a href="#o2ⁿ--complexidade-exponencial-" class="table-of-contents__link toc-highlight"><strong>O(2ⁿ) – Complexidade Exponencial →</strong></a></li><li><a href="#on--complexidade-de-raiz-quadrada-" class="table-of-contents__link toc-highlight"><strong>O(√n) – Complexidade de Raiz Quadrada →</strong></a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Documentação</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/brain/docs/intro">Introdução</a></li></ul></div><div class="col footer__col"><div class="footer__title">Social</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://linkedin.com/in/ramonxm" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/ramonxm" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://x.com/ramonxavierm" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Ramon Xavier. Feito com Docusaurus.</div></div></div></footer></div>
</body>
</html>